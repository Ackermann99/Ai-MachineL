{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://bitbucket.org/jadslim/german-traffic-signs\n",
    "\n",
    "!ls german-traffic-signs\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"german-traffic-signs/train.p\", \"rb\") as f:\n",
    "  train_data = pickle.load(f)\n",
    "with open(\"german-traffic-signs/valid.p\", \"rb\") as f:\n",
    "  val_data = pickle.load(f)\n",
    "with open(\"german-traffic-signs/test.p\", \"rb\") as f:\n",
    "  test_data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = train_data[\"features\"], train_data[\"labels\"]\n",
    "X_val, y_val = val_data[\"features\"], val_data[\"labels\"]\n",
    "X_test, y_test = test_data[\"features\"], test_data[\"labels\"]\n",
    "\n",
    "# print(type(train_data))\n",
    "# print(train_data[\"features\"])\n",
    "# print(train_data[\"labels\"])\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0], \"number of image is not equal to the number of labels\"\n",
    "assert X_val.shape[0] == y_val.shape[0], \"number of image is not equal to the number of labels\"\n",
    "assert X_test.shape[0] == y_test.shape[0], \"number of image is not equal to the number of labels\"\n",
    "assert X_train.shape[1:] == (32, 32, 3), \"dimension of the images are not 32 x 32 x 3\"\n",
    "assert X_val.shape[1:] == (32, 32, 3), \"dimension of the images are not 32 x 32 x 3\"\n",
    "assert X_test.shape[1:] == (32, 32, 3), \"dimension of the images are not 32 x 32 x 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"german-traffic-signs/signnames.csv\")\n",
    "\n",
    "num_of_samples = []\n",
    " \n",
    "cols = 5\n",
    "num_classes = 43\n",
    " \n",
    "fig, axs = plt.subplots(nrows=num_classes, ncols = cols, figsize=(5, 50))\n",
    "fig.tight_layout()\n",
    "for i in range(cols):\n",
    "    for j, row in data.iterrows():\n",
    "        x_selected = X_train[y_train == j]\n",
    "        axs[j][i].imshow(x_selected[random.randint(0, (len(x_selected) - 1)), :, :], cmap=plt.get_cmap(\"gray\"))\n",
    "        axs[j][i].axis(\"off\")\n",
    "        if i == 2:\n",
    "            axs[j][i].set_title(str(j) + \"-\" + row[\"SignName\"])\n",
    "            num_of_samples.append(len(x_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_of_samples)\n",
    "plt.figure(figsize=(18, 7))\n",
    "plt.bar(range(0, num_classes), num_of_samples)\n",
    "plt.title(\"Distribution of the training dataset\")\n",
    "plt.xlabel(\"Class number\")\n",
    "plt.ylabel(\"Number of images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "plt.imshow(X_train[1050])\n",
    "plt.axis(\"off\")\n",
    "print(y_train[1050])\n",
    "\n",
    "\"\"\"\n",
    "Image preprocessing step 1 : Convert to grayscale\n",
    "\"\"\"\n",
    "\n",
    "def grayscale(img):\n",
    "  return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img = cv2.bitwise_not(grayscale(X_train[1000]))\n",
    "plt.imshow(img, cmap=plt.get_cmap(\"gray\"))\n",
    "plt.axis(\"off\")\n",
    "print(img.shape)\n",
    "\n",
    "\"\"\"\n",
    "Image preprocessing step 2 : Apply equalisation histogram\n",
    "\"\"\"\n",
    "\n",
    "def equalise(img):\n",
    "  return cv2.equalizeHist(img)    #this function works best with grayscale image\n",
    "\n",
    "img = equalise(img)\n",
    "plt.imshow(img, cmap=plt.get_cmap(\"gray\"))\n",
    "plt.axis(\"off\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Applying steps over entire dataset\n",
    "\"\"\"\n",
    "\n",
    "def preprocessing(img):\n",
    "  img = grayscale(img)\n",
    "  img = equalise(img)\n",
    "  img = img/255   #normalisation\n",
    "  return img\n",
    "\n",
    "X_train = np.array(list(map(preprocessing, X_train)))\n",
    "X_val = np.array(list(map(preprocessing, X_val)))\n",
    "X_test = np.array(list(map(preprocessing, X_test)))\n",
    "\n",
    "# plt.imshow(X_train[500], cmap=plt.get_cmap(\"gray\"))\n",
    "# plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping \n",
    "X_train = X_train.reshape(34799, 32, 32, 1)\n",
    "X_val = X_val.reshape(4410, 32, 32, 1)\n",
    "X_test = X_test.reshape(12630, 32, 32, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "applying data augmentation over the training set\n",
    "\"\"\"\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             zoom_range=0.2,\n",
    "                             shear_range=0.1,\n",
    "                             rotation_range=10)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing augmented samples\n",
    "\n",
    "batches = datagen.flow(X_train, y_train, batch_size=20)\n",
    "X_batch, y_batch = next(batches)\n",
    "\n",
    "fig, axs = plt.subplots(1, 15, figsize=(20, 5))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(15):\n",
    "  axs[i].imshow(X_batch[i].reshape(32, 32), cmap=plt.get_cmap(\"gray\"))\n",
    "  axs[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot-encoding labels\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_val = to_categorical(y_val, 43)\n",
    "y_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining a modified model to fit the data\n",
    "\"\"\"\n",
    "\n",
    "def modified_model():\n",
    "  model = Sequential()\n",
    "\n",
    "  #feature learning\n",
    "  model.add(Conv2D(60, (5, 5), input_shape= (32, 32, 1), activation=\"relu\")) \n",
    "  model.add(Conv2D(60, (5, 5), activation=\"relu\"))    \n",
    "  model.add(MaxPooling2D(pool_size= (2, 2)))  \n",
    "\n",
    "  model.add(Conv2D(30, (3, 3), activation= \"relu\"))\n",
    "  model.add(Conv2D(30, (3, 3), activation= \"relu\"))     \n",
    "  model.add(MaxPooling2D(pool_size= (2, 2)))    \n",
    "  \n",
    "  # model.add(Dropout(0.5))    #dropout layer\n",
    "  \n",
    "  #Classification\n",
    "  model.add(Flatten())  \n",
    "  model.add(Dense(500, activation= \"relu\"))    #hidden layer \n",
    "  model.add(Dropout(0.5))    #dropout layer\n",
    "  model.add(Dense(num_classes, activation= \"softmax\"))    #output layer\n",
    "  \n",
    "  model.compile(Adam(lr = 0.001), loss=\"categorical_crossentropy\", metrics= [\"accuracy\"])\n",
    "  return model\n",
    "\n",
    "model = modified_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "steps_per_epoch = X_train.shape[0]/batch_size\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), steps_per_epoch=steps_per_epoch, epochs=10, validation_data=(X_val, y_val), shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"])    \n",
    "plt.plot(history.history[\"val_accuracy\"])   \n",
    "plt.legend([\"accuracy\", \"val_accuracy\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])     \n",
    "plt.plot(history.history[\"val_loss\"]) \n",
    "plt.legend([\"loss\", \"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(type(score))\n",
    "print(\"TEST SCORE : \", score[0])\n",
    "print(\"TEST ACCURACY : \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing new image\n",
    "import requests\n",
    "from PIL import Image     #Python image library\n",
    "\n",
    "url = \"https://c8.alamy.com/comp/J2MRAJ/german-road-sign-bicycles-crossing-J2MRAJ.jpg\"\n",
    "response = requests.get(url, stream=True)\n",
    "img = Image.open(response.raw)\n",
    "plt.imshow(img, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img_array = np.asarray(img)     #converts the input to array \n",
    "print(img_array.shape)\n",
    "img_resized = cv2.resize(img_array, (32, 32))\n",
    "image = preprocessing(img_resized)\n",
    "plt.imshow(image, cmap = plt.get_cmap(\"gray\"))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.reshape(1, 32, 32, 1)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" prediction \"\"\"\n",
    "prediction = np.argmax(model.predict(image), axis=-1)\n",
    "print(\"Predicted Digit : \", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
